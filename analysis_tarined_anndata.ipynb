{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trajectory inference for hematopoiesis in mouse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstructing myeloid and erythroid differentiation for data of [Paul et al. (2015)](http://doi.org/10.1016/j.cell.2015.11.013)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pl\n",
    "from matplotlib import rcParams\n",
    "import scanpy as sc\n",
    "import utils as ut\n",
    "import glob\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.stats import pearsonr\n",
    "from utils import de_score\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy.stats import ranksums,ttest_ind\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.settings.verbosity = 0  # verbosity: errors (0), warnings (1), info (2), hints (3)\n",
    "#sc.logging.print_versions()\n",
    "sc.settings.set_figure_params(dpi=300, frameon=False, figsize=(3, 3), facecolor='white')  # low dpi (dots per inch) yields small inline figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all files in the directoty\n",
    "h5ad_list = glob.glob(\"D:/pyws/trainsource/saved/adata/review/*.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5ad_list[4].split(\"1214\")[0].split(\"\\\\\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5ad_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CELL_TYPE_KEY = {\"GSE117872_HN137\":\"cell_color\",\"GSE117872_HN120\":\"cell_color\",\"GSE110894\":\"Sample name\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f= h5ad_list[0]\n",
    "adata = sc.read_h5ad(filename=f)\n",
    "adata.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h5ad_list = [h5ad_list[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generated 3 figures comparing before, after tarnsfer, ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And it will save the F1 score before and after the transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random score test\n",
    "def ran_test_score(adata,n_iters=1000):\n",
    "    ran_results1 = []\n",
    "    ran_results2 = []\n",
    "\n",
    "    s_score,s_pval = pearsonr(adata.obs[\"1_score\"],adata.obs[\"Sensitive_score\"])\n",
    "    r_score,r_pval = pearsonr(adata.obs[\"0_score\"],adata.obs[\"Resistant_score\"])\n",
    "\n",
    "\n",
    "    for i in range(0,n_iters):\n",
    "\n",
    "        gl1 = random.sample(list(adata.var.index),50)\n",
    "        adata=sc.tl.score_genes(adata, gene_list=gl1,score_name=\"l1_score\",copy=True)\n",
    "\n",
    "        rand_score1,rand_pval1 = pearsonr(adata.obs[\"l1_score\"],adata.obs[\"Sensitive_score\"])\n",
    "        rand_score2,rand_pval2 = pearsonr(adata.obs[\"l1_score\"],adata.obs[\"Resistant_score\"])\n",
    "\n",
    "        ran_results1.append(rand_score1)\n",
    "        ran_results2.append(rand_score2)\n",
    "        \n",
    "        \n",
    "    return adata,ran_results1, s_score,s_pval ,ran_results2,r_score,r_pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (auc, average_precision_score,\n",
    "                             classification_report, mean_squared_error,\n",
    "                             precision_recall_curve, r2_score, roc_auc_score)\n",
    "\n",
    "names = []\n",
    "score = []\n",
    "model = []\n",
    "\n",
    "for f in h5ad_list:\n",
    "    \n",
    "    \n",
    "    adata = sc.read_h5ad(filename=f)\n",
    "    pretrain_label = adata.obs['sens_label_pret']\n",
    "    sens_label = adata.obs['sens_label']\n",
    "    \n",
    "        \n",
    "    print(adata.obs.columns)\n",
    "\n",
    "    grouth_truth = adata.obs['sensitive']\n",
    "    sens_pb_pret = adata.obs['sens_preds_pret']\n",
    "    sens_label_pret = adata.obs['sens_label_pret']\n",
    "    sens_pb = adata.obs['sens_preds']\n",
    "\n",
    "    name = f.split(\"1214\")[0].split(\"\\\\\")[1]\n",
    "    \n",
    "    if(name==\"GSE110894\"):\n",
    "        adata=adata[(adata.obs[\"Sample name\"] != \"EMPTY\") & \\\n",
    "                    (adata.obs[\"Sample name\"] != \"EMPTY \") ,: ]\n",
    "    \n",
    "    \n",
    "    \n",
    "    report_dict_pret = classification_report(grouth_truth, pretrain_label, output_dict=True)\n",
    "    classification_report_pret_df = pd.DataFrame(report_dict_pret).T\n",
    "    f1score_pret = report_dict_pret['weighted avg']['f1-score']\n",
    "    ap_pret = average_precision_score(grouth_truth, sens_pb_pret)\n",
    "    auroc_pret = roc_auc_score(grouth_truth, sens_label_pret)\n",
    "\n",
    "    \n",
    "    report_dict = classification_report(grouth_truth, sens_label, output_dict=True)\n",
    "    classification_report_df = pd.DataFrame(report_dict).T\n",
    "    f1score = report_dict['weighted avg']['f1-score']\n",
    "    ap = average_precision_score(grouth_truth, sens_pb)\n",
    "    auroc = roc_auc_score(grouth_truth, sens_label)\n",
    "    \n",
    "    names.append(name)\n",
    "    score.append(f1score_pret)\n",
    "    model.append(\"before\")\n",
    "    \n",
    "    names.append(name)\n",
    "    score.append(f1score)\n",
    "    model.append(\"transfer\")\n",
    "\n",
    "    result = pd.DataFrame({\"f1\":[f1score_pret,f1score],\n",
    "                          \"ap\":[ap_pret,ap],\n",
    "                          \"auroc\":[auroc_pret,auroc]},index=[\"pretrain\",\"transfer\"])\n",
    "    \n",
    "    print()\n",
    "    # Save the figure\n",
    "    sc.pl.umap(adata,color=['sens_preds_pret','sens_preds','sensitive'],save=\"report_compare\"+name + '.pdf')\n",
    "    # Save the f1 score before and after\n",
    "    result.to_csv(\"saved/results/report_compare\"+name + '.csv')\n",
    "    \n",
    "    # Cal pred senstivie score\n",
    "    adata = ut.de_score(adata,clustername='sens_label')\n",
    "    \n",
    "    adata,s_ran, s_score,s_pval ,r_ran,r_score,r_pval = ran_test_score(adata,1000)\n",
    "    \n",
    "    plt.hist(s_ran)\n",
    "    plt.xlim(xmin=-1, xmax = 1)\n",
    "    plt.axvline(s_score, color='r', linestyle='dashed', linewidth=1)\n",
    "    plt.axvline(np.mean(s_ran), color='k', linestyle='dashed', linewidth=1)\n",
    "    min_ylim, max_ylim = plt.ylim()\n",
    "\n",
    "    plt.text(-0.95, max_ylim*0.8, 'p < 0.001', color='k')\n",
    "    plt.text(-0.95, max_ylim*0.9, 'r: {:.2f}'.format(s_score), color='k')\n",
    "\n",
    "    plt.savefig(\"saved/figures/random_sensitive_gene\"+name + '.svg')\n",
    "    plt.clf()\n",
    "    \n",
    "    \n",
    "    plt.hist(r_ran)\n",
    "    plt.xlim(xmin=-1, xmax = 1)\n",
    "    plt.axvline(r_score, color='r', linestyle='dashed', linewidth=1)\n",
    "    plt.axvline(np.mean(s_ran), color='k', linestyle='dashed', linewidth=1)\n",
    "    min_ylim, max_ylim = plt.ylim()\n",
    "\n",
    "    plt.text(-0.95, max_ylim*0.8, 'p < 0.001', color='k')\n",
    "    plt.text(-0.95, max_ylim*0.9, 'r: {:.2f}'.format(r_score), color='k')\n",
    "    plt.savefig(\"saved/figures/random_resistant_gene\"+name + '.svg')\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_compare = pd.DataFrame({\"data\":names,\n",
    "                      \"transfer\":model,\n",
    "                      \"score\":score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the umap highlighting the wrong predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = adata.obs[\"sensitive\"] != adata.obs[\"sens_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['wrong'] = pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs.loc[idx,'wrong'] = \"Wrong\"\n",
    "adata.obs['wrong'] = adata.obs.wrong.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc.pl.umap(adata,color=['ABCC2', 'BIRC3', 'CCND1', 'CFLAR', 'CHEK2', 'ERCC1', 'MT2A', 'POLB', 'GCLC','GSTT2','TP53','MDM2','RAC1'],size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adata,color=\"wrong\",size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = adata.obs[[CELL_TYPE_KEY[name],\"wrong\"]]\\\n",
    ".groupby([CELL_TYPE_KEY[name]])\\\n",
    ".aggregate(['count','size'])\\\n",
    ".reset_index()\n",
    "df['data'] = name\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Barplot of score before and after the transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sc.settings.set_figure_params(dpi=800, frameon=False, figsize=(5, 3), facecolor='white')  # low dpi (dots per inch) yields small inline figures\n",
    "g = sns.barplot(x=\"data\", y=\"score\",hue=\"transfer\",palette=\"Greens_r\",\n",
    "                data=result_compare)\n",
    "plt.legend().remove()\n",
    "sns.despine(bottom = True, left = True)\n",
    "\n",
    "plt.setp(g.get_xticklabels(), rotation=-45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 2 A panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs[\"pred_binary\"] = adata.obs[\"sens_label\"]\n",
    "adata.obs.sens_label = adata.obs.sens_label.cat.rename_categories({1:\"Sensitive\", 0:\"Resistant\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adata.obs.sensitivity = adata.obs.sensitivity.cat.rename_categories({\"Sensitive\":\"Response\", \"Resistant\":\"Resistant\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs=adata.obs.rename(columns={\"sensitivity\": \"Ground Truth\", \"sens_label\": \"Prediction\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.settings.set_figure_params(dpi=250, frameon=False, figsize=(3, 3), facecolor='white')  # low dpi (dots per inch) yields small inline figures\n",
    "ax = sc.pl.umap(adata,color=['Ground Truth',\"Prediction\"],size=40,show=False,wspace=0.1)\n",
    "ax[0].legend().remove()\n",
    "ax[1].legend(loc ='lower center',bbox_to_anchor=(-0.2, 0),frameon=False) \n",
    "plt.savefig(\"saved/figures/figure2A_1\"+name + \".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs[\"Sample name\"] = adata.obs[\"Sample name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sc.pl.umap(adata,color=[\"rest_preds\"],size=40,palette=\"Paired\",show=False)\n",
    "plt.savefig(\"saved/figures/figure2A_2\"+name + \".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs[\"Sample name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs[\"Sample name\"] =adata.obs[\"Sample name\"].cat.rename_categories({'101 CELL CONTROL':\"control\", \\\n",
    "                                                \"MA9 IBET RESISTANT CELLS\":\"IBET Resistant\",\\\n",
    "                                              'MA9 IBET RESISTANT CELLS- WITHDRAWAL':\"IBET Resistant(withdraw)\",\\\n",
    "                                              'MA9 PARENTALS DMSO':\"IBET DMSO\",\\\n",
    "                                              \"MA9 PARENTALS IBET 400NMOL\":\"IBET 400NMOL\"\n",
    "                                               })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = adata[adata.obs[\"Sample name\"]!=\"control\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sc.pl.umap(adata,color=[CELL_TYPE_KEY[name]],size=40,palette=\"Paired\",show=False)\n",
    "ax.legend(loc ='lower center',bbox_to_anchor=(0.5, -0.55),frameon=False) \n",
    "plt.savefig(\"saved/figures/figure2A_3\"+name + \".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sc.pl.umap(adata,color=['Ground Truth',\"Prediction\",CELL_TYPE_KEY[name]],size=25,palette=\"Paired\",show=False)\n",
    "ax[0].legend(loc ='lower center',bbox_to_anchor=(0.5, -0.25)) \n",
    "ax[1].legend(loc ='lower center',bbox_to_anchor=(0.5, -0.25)) \n",
    "ax[2].legend(loc ='lower center',bbox_to_anchor=(0.5, -0.5)) \n",
    "plt.savefig(\"figure2A_compare\"+name + \".pdf\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = ut.de_score(adata,clustername='pred_binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens_score,s_pval = pearsonr(adata.obs[\"1_score\"],adata.obs[\"Sensitive_score\"])\n",
    "resistant_score,r_pval = pearsonr(adata.obs[\"0_score\"],adata.obs[\"Resistant_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sc.pl.umap(adata,color=[\"1_score\",\"Sensitive_score\"],size=40,palette=\"Set2\",show=False)\n",
    "ax[0].legend(loc ='lower center',bbox_to_anchor=(0.5, -0.55),frameon=False) \n",
    "ax[1].legend(loc ='lower center',bbox_to_anchor=(0.5, -0.55),frameon=False) \n",
    "plt.savefig(\"saved/figures/figure2A_4\"+name + \".pdf\")\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = sc.pl.umap(adata,color=[\"0_score\",\"Resistant_score\"],size=40,palette=\"flare\",show=False)\n",
    "ax[0].legend(loc ='lower center',bbox_to_anchor=(0.5, -0.55),frameon=False) \n",
    "ax[1].legend(loc ='lower center',bbox_to_anchor=(0.5, -0.55),frameon=False) \n",
    "plt.savefig(\"saved/figures/figure2A_5\"+name + \".pdf\")\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# ran_results1 = []\n",
    "# ran_results2 = []\n",
    "\n",
    "# s_results = []\n",
    "# r_results = []\n",
    "\n",
    "# sc.settings.verbosity = 0\n",
    "\n",
    "# for i in range(0,1000):\n",
    "\n",
    "#     gl1 = random.sample(list(adata.var.index),50)\n",
    "#     gl2 = random.sample(list(adata.var.index),50)\n",
    "#     cl1 = random.sample(list(adata.obs.index),200)\n",
    "\n",
    "#     cdata = adata[cl1,]\n",
    "\n",
    "#     cdata=sc.tl.score_genes(cdata, gene_list=gl1,score_name=\"l1_score\",copy=True)\n",
    "#     #cdata=sc.tl.score_genes(cdata, gene_list=gl2,score_name=\"l2_score\",copy=True)\n",
    "\n",
    "#     rand_score1,rand_pval1 = pearsonr(cdata.obs[\"l1_score\"],cdata.obs[\"Sensitive_score\"])\n",
    "#     rand_score2,rand_pval2 = pearsonr(cdata.obs[\"l1_score\"],cdata.obs[\"Resistant_score\"])\n",
    "\n",
    "#     #sens_score,s_pval = pearsonr(adata.obs[\"l1_score\"],adata.obs[\"l1_score\"])\n",
    "#     ran_results1.append(rand_score1)\n",
    "#     ran_results2.append(rand_score2)\n",
    "\n",
    "#     s_score,s_pval = pearsonr(cdata.obs[\"1_score\"],cdata.obs[\"Sensitive_score\"])\n",
    "#     s_results.append(s_score)\n",
    "    \n",
    "#     r_score,r_pval = pearsonr(cdata.obs[\"0_score\"],cdata.obs[\"Resistant_score\"])\n",
    "#     r_results.append(r_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ran_test_score(adata,n_iters=1000):\n",
    "    ran_results1 = []\n",
    "    ran_results2 = []\n",
    "\n",
    "    s_score,s_pval = pearsonr(adata.obs[\"1_score\"],adata.obs[\"Sensitive_score\"])\n",
    "    r_score,r_pval = pearsonr(adata.obs[\"0_score\"],adata.obs[\"Resistant_score\"])\n",
    "\n",
    "\n",
    "    for i in range(0,n_iters):\n",
    "\n",
    "        gl1 = random.sample(list(adata.var.index),50)\n",
    "        adata=sc.tl.score_genes(adata, gene_list=gl1,score_name=\"l1_score\",copy=True)\n",
    "\n",
    "        rand_score1,rand_pval1 = pearsonr(adata.obs[\"l1_score\"],adata.obs[\"Sensitive_score\"])\n",
    "        rand_score2,rand_pval2 = pearsonr(adata.obs[\"l1_score\"],adata.obs[\"Resistant_score\"])\n",
    "\n",
    "        ran_results1.append(rand_score1)\n",
    "        ran_results2.append(rand_score2)\n",
    "        \n",
    "        \n",
    "    return adata,ran_results1, s_score,s_pval ,ran_results2,r_score,r_pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata,s_ran, s_score,s_pval ,r_ran,r_score,r_pval = ran_test_score(adata,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_ran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1,p1 = ranksums(s_results, ran_results1,alternative =\"greater\")\n",
    "w2,p2 = ranksums(r_results, ran_results2,alternative =\"greater\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(ran_results1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npr_ran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(r_ran)\n",
    "plt.xlim(xmin=-1, xmax = 1)\n",
    "plt.axvline(r_score, color='r', linestyle='dashed', linewidth=1)\n",
    "plt.axvline(np.mean(r_ran), color='k', linestyle='dashed', linewidth=1)\n",
    "\n",
    "min_ylim, max_ylim = plt.ylim()\n",
    "#plt.text(-1, max_ylim*0.7, 'Mean: {:.2f}'.format(np.mean(r_ran)))\n",
    "plt.text(-0.95, max_ylim*0.8, 'p < 0.001', color='k')\n",
    "plt.text(-0.95, max_ylim*0.9, 'r: {:.2f}'.format(r_score), color='k')\n",
    "plt.savefig(\"saved/figures/random_resistant_gene\"+name + '.svg')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(s_ran)\n",
    "plt.xlim(xmin=-1, xmax = 1)\n",
    "plt.axvline(s_score, color='r', linestyle='dashed', linewidth=1)\n",
    "plt.axvline(np.mean(s_ran), color='k', linestyle='dashed', linewidth=1)\n",
    "\n",
    "min_ylim, max_ylim = plt.ylim()\n",
    "#plt.text(-1, max_ylim*0.7, 'Mean: {:.2f}'.format(np.mean(r_ran)))\n",
    "plt.text(-0.95, max_ylim*0.8, 'p < 0.001', color='k')\n",
    "plt.text(-0.95, max_ylim*0.9, 'r: {:.2f}'.format(s_score), color='k')\n",
    "plt.savefig(\"saved/figures/random_senstive_gene\"+name + '.svg')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_ind(s_results, ran_results1,alternative =\"greater\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(s_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(r_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_pval"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
