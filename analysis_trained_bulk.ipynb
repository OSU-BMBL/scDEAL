{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same as the scmodel.py"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "To show the umap embedding after the transfer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from decimal import Decimal\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import torch\n",
    "from captum.attr import IntegratedGradients\n",
    "from numpy.lib.function_base import gradient\n",
    "from sklearn import preprocessing\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import (auc, average_precision_score,\n",
    "                             classification_report, mean_squared_error,\n",
    "                             precision_recall_curve, r2_score, roc_auc_score)\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch import nn, optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from scipy.stats import pearsonr\n",
    "import DaNN.mmd as mmd\n",
    "import scanpypip.preprocessing as pp\n",
    "import trainers as t\n",
    "import utils as ut\n",
    "from models import (AEBase, CVAEBase, DaNN, Predictor, PretrainedPredictor,\n",
    "                    PretrainedVAEPredictor, TargetModel, VAEBase)\n",
    "from scanpypip.utils import get_de_dataframe\n",
    "from trajectory import trajectory\n",
    "from sklearn.feature_selection import SelectKBest,SelectFdr\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "\n",
    "DATA_MAP={\n",
    "\"GSE117872\":\"data/GSE117872/GSE117872_good_Data_TPM.txt\",\n",
    "\"GSE117309\":'data/GSE117309/filtered_gene_bc_matrices_HBCx-22/hg19/',\n",
    "\"GSE117309_TAMR\":'data/GSE117309/filtered_gene_bc_matrices_HBCx22-TAMR/hg19/',\n",
    "\"GSE121107\":'data/GSE121107/GSM3426289_untreated_out_gene_exon_tagged.dge.txt',\n",
    "\"GSE121107_1H\":'data/GSE121107/GSM3426290_entinostat_1hr_out_gene_exon_tagged.dge.txt',\n",
    "\"GSE121107_6H\":'data/GSE121107/GSM3426291_entinostat_6hr_out_gene_exon_tagged.dge.txt',\n",
    "\"GSE111014\":'data/GSE111014/',\n",
    "\"GSE110894\":\"data/GSE110894/GSE110894.csv\",\n",
    "\"GSE122843\":\"data/GSE122843/GSE122843.txt\",\n",
    "\"GSE112274\":\"data/GSE112274/GSE112274_cell_gene_FPKM.csv\",\n",
    "\"GSE116237\":\"data/GSE116237/GSE116237_bulkRNAseq_expressionMatrix.txt\",\n",
    "\"GSE108383\":\"data/GSE108383/GSE108383_Melanoma_fluidigm.txt\",\n",
    "\"GSE140440\":\"data/GSE140440/GSE140440.csv\",\n",
    "\"GSE129730\":\"data/GSE129730/GSE129730.h5ad\",\n",
    "\"GSE149383\":\"data/GSE149383/erl_total_data_2K.csv\",\n",
    "\"GSE110894_small\":\"data/GSE110894/GSE110894_small.h5ad\",\n",
    "\"MIX-Seq\":\"data/10298696\"\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Path of the .pkl files in sc_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"F://ws//pyws//scDEAL//saved//bulk_pre//1214*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F://ws//pyws//scDEAL//saved//bulk_pre\\\\1214data_GSE110894_drug_I.BET.762_bottle_128_edim_512,256_pdim_256,128_model_DAE_dropout_0.1_gene_T_lr_0.01_mod_new_sam_downsampling',\n",
       " 'F://ws//pyws//scDEAL//saved//bulk_pre\\\\1214data_GSE112274_drug_GEFITINIB_bottle_64_edim_512,256_pdim_256,128_model_DAE_dropout_0.1_gene_T_lr_0.1_mod_new_sam_no',\n",
       " 'F://ws//pyws//scDEAL//saved//bulk_pre\\\\1214data_GSE117872HN120_drug_CISPLATIN_bottle_32_edim_256,128_pdim_128,64_model_DAE_dropout_0.3_gene_T_lr_0.5_mod_new_sam_SMOTE',\n",
       " 'F://ws//pyws//scDEAL//saved//bulk_pre\\\\1214data_GSE117872HN137_drug_CISPLATIN_bottle_64_edim_256,128_pdim_128,64_model_DAE_dropout_0.3_gene_T_lr_0.1_mod_new_sam_upsampling',\n",
       " 'F://ws//pyws//scDEAL//saved//bulk_pre\\\\1214data_GSE140440_drug_DOCETAXEL_bottle_512_edim_256,128_pdim_256,128_model_DAE_dropout_0.3_gene_T_lr_0.01_mod_new_sam_no',\n",
       " 'F://ws//pyws//scDEAL//saved//bulk_pre\\\\1214data_GSE149383_drug_ERLOTINIB_bottle_512_edim_512,256_pdim_256,128_model_DAE_dropout_0.1_gene_T_lr_0.1_mod_new_sam_SMOTE']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECTED_FILES = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "# data \n",
    "parser.add_argument('--data', type=str, default='data/ALL_expression.csv',help='Path of the bulk RNA-Seq expression profile')\n",
    "parser.add_argument('--label', type=str, default='data/TOTAL_label_binary_wf.csv',help='Path of the processed bulk RNA-Seq drug screening annotation')\n",
    "parser.add_argument('--result', type=str, default='saved/results/result_',help='Path of the training result report files')\n",
    "parser.add_argument('--drug', type=str, default='I.BET.762',help='Name of the selected drug, should be a column name in the input file of --label')\n",
    "parser.add_argument('--missing_value', type=int, default=1,help='The value filled in the missing entry in the drug screening annotation, default: 1')\n",
    "parser.add_argument('--test_size', type=float, default=0.2,help='Size of the test set for the bulk model traning, default: 0.2')\n",
    "parser.add_argument('--valid_size', type=float, default=0.2,help='Size of the validation set for the bulk model traning, default: 0.2')\n",
    "parser.add_argument('--var_genes_disp', type=float, default=None,help='Dispersion of highly variable genes selection when pre-processing the data. \\\n",
    "                     If None, all genes will be selected .default: None')\n",
    "parser.add_argument('--sampling', type=str, default=None,help='Samping method of training data for the bulk model traning. \\\n",
    "                    Can be upsampling, downsampling, or SMOTE. default: None')\n",
    "parser.add_argument('--PCA_dim', type=int, default=0,help='Number of components of PCA  reduction before training. If 0, no PCA will be performed. Default: 0')\n",
    "\n",
    "# trainv\n",
    "parser.add_argument('--bulk_encoder','-e', type=str, default='saved/bulk_encoder/',help='Path of the pre-trained encoder in the bulk level')\n",
    "parser.add_argument('--pretrain', type=int, default=1,help='Whether to perform pre-training of the encoder. 0: do not pretraing, 1: pretrain. Default: 0')\n",
    "parser.add_argument('--lr', type=float, default=1e-2,help='Learning rate of model training. Default: 1e-2')\n",
    "parser.add_argument('--epochs', type=int, default=500,help='Number of epoches training. Default: 500')\n",
    "parser.add_argument('--batch_size', type=int, default=200,help='Number of batch size when training. Default: 200')\n",
    "parser.add_argument('--bottleneck', type=int, default=32,help='Size of the bottleneck layer of the model. Default: 32')\n",
    "parser.add_argument('--dimreduce', type=str, default=\"AE\",help='Encoder model type. Can be AE or VAE. Default: AE')\n",
    "parser.add_argument('--freeze_pretrain', type=int, default=0,help='Fix the prarmeters in the pretrained model. 0: do not freeze, 1: freeze. Default: 0')\n",
    "parser.add_argument('--encoder_h_dims', type=str, default=\"512,256\",help='Shape of the encoder. Each number represent the number of neuron in a layer. \\\n",
    "                    Layers are seperated by a comma. Default: 512,256')\n",
    "parser.add_argument('--predictor_h_dims', type=str, default=\"16,8\",help='Shape of the predictor. Each number represent the number of neuron in a layer. \\\n",
    "                    Layers are seperated by a comma. Default: 16,8')\n",
    "parser.add_argument('--VAErepram', type=int, default=1)\n",
    "parser.add_argument('--data_name', type=str, default=\"GSE110894\",help='Accession id for testing data, only support pre-built data.')\n",
    "# misc\n",
    "parser.add_argument('--bulk_model', '-p',  type=str, default='saved/bulk_pre/',help='Path of the trained prediction model in the bulk level')\n",
    "parser.add_argument('--log', '-l',  type=str, default='saved/logs/log',help='Path of training log')\n",
    "parser.add_argument('--load_source_model',  type=int, default=0,help='Load a trained bulk level or not. 0: do not load, 1: load. Default: 0')\n",
    "parser.add_argument('--mod', type=str, default='new',help='heterogeneous')\n",
    "parser.add_argument('--printgene', type=str, default='T',help='wether print critical gene')\n",
    "parser.add_argument('--dropout', type=float, default=0.3,help='dropout')\n",
    "\n",
    "#\n",
    "args, unknown = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pre\\\\1214data', 'drug', 'bottle', 'edim', 'pdim', 'model', 'dropout', 'gene', 'lr', 'mod', 'sam']\n",
      "['F://ws//pyws//scDEAL//saved//bulk', 'GSE117872HN137', 'CISPLATIN', '64', '256,128', '128,64', 'DAE', '0.3', 'T', '0.1', 'new', 'upsampling']\n"
     ]
    }
   ],
   "source": [
    "## Testing the args covering\n",
    "selected_model = files[SELECTED_FILES]\n",
    "split_name = selected_model.split(\"_\")\n",
    "print(split_name[1::2])\n",
    "print(split_name[0::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_names = (split_name[1::2])\n",
    "paras = (split_name[0::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F://ws//pyws//scDEAL//saved//bulk',\n",
       " 'GSE117872HN137',\n",
       " 'CISPLATIN',\n",
       " '64',\n",
       " '256,128',\n",
       " '128,64',\n",
       " 'DAE',\n",
       " '0.3',\n",
       " 'T',\n",
       " '0.1',\n",
       " 'new',\n",
       " 'upsampling']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pre\\\\1214data',\n",
       " 'drug',\n",
       " 'bottle',\n",
       " 'edim',\n",
       " 'pdim',\n",
       " 'model',\n",
       " 'dropout',\n",
       " 'gene',\n",
       " 'lr',\n",
       " 'mod',\n",
       " 'sam']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.encoder_h_dims = paras[4]\n",
    "args.predictor_h_dims = paras[5]\n",
    "args.bottleneck = int(paras[3])\n",
    "args.drug = paras[2]\n",
    "args.dropout = float(paras[7])\n",
    "\n",
    "if(paras[0].find(\"GSE117872\")>=0):\n",
    "    args.target_data = \"GSE117872\"\n",
    "    args.batch_id = paras[0].split(\"GSE117872\")[1]\n",
    "elif(paras[0].find(\"MIX-Seq\")>=0):\n",
    "    args.target_data = \"MIX-Seq\"\n",
    "    args.batch_id = paras[0].split(\"MIX-Seq\")[1]    \n",
    "else:\n",
    "    args.target_data = paras[0]\n",
    "    \n",
    "args.target_model_path = selected_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read parameters\n",
    "# Extract parameters\n",
    "epochs = args.epochs\n",
    "dim_au_out = args.bottleneck #8, 16, 32, 64, 128, 256,512\n",
    "select_drug = args.drug\n",
    "na = args.missing_value\n",
    "data_path = args.data\n",
    "label_path = args.label\n",
    "test_size = args.test_size\n",
    "valid_size = args.valid_size\n",
    "g_disperson = args.var_genes_disp\n",
    "log_path = args.log\n",
    "batch_size = args.batch_size\n",
    "encoder_hdims = args.encoder_h_dims.split(\",\")\n",
    "preditor_hdims = args.predictor_h_dims.split(\",\")\n",
    "reduce_model = args.dimreduce\n",
    "sampling = args.sampling\n",
    "PCA_dim = args.PCA_dim\n",
    "\n",
    "encoder_hdims = list(map(int, encoder_hdims) )\n",
    "preditor_hdims = list(map(int, preditor_hdims) )\n",
    "load_model = bool(args.load_source_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "para = \"1214data_\"+args.data_name+\"_drug_\"+args.drug+\"_bottle_\"+str(args.bottleneck)+\"_edim_\"+args.encoder_h_dims+\"_pdim_\"+args.predictor_h_dims+\"_model_\"+reduce_model+\"_dropout_\"+str(args.dropout)+\"_gene_\"+args.printgene+\"_lr_\"+str(args.lr)+\"_mod_\"+args.mod+\"_sam_\"+str(args.sampling)\n",
    "#(para)\n",
    "now=time.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "#print(preditor_path )\n",
    "#model_path = args.bulk_model + para \n",
    "preditor_path = args.bulk_model + para \n",
    "bulk_encoder = args.bulk_encoder+para\n",
    "# Read data\n",
    "data_r=pd.read_csv(data_path,index_col=0)\n",
    "label_r=pd.read_csv(label_path,index_col=0)\n",
    "#label_r=label_r.fillna(na)\n",
    "ut.save_arguments(args,now)\n",
    "\n",
    "\n",
    "# Initialize logging and std out\n",
    "out_path = log_path+now+\".err\"\n",
    "log_path = log_path+now+\".log\"\n",
    "\n",
    "out=open(out_path,\"w\")\n",
    "sys.stderr=out\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                filename=log_path,\n",
    "                filemode='a',\n",
    "                format=\n",
    "                '%(asctime)s - %(pathname)s[line:%(lineno)d] - %(levelname)s: %(message)s'\n",
    "                )\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "\n",
    "#logging.info(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "bulk_X_allRensor torch.Size([1208, 15962])\n"
     ]
    }
   ],
   "source": [
    "# Filter out na values\n",
    "selected_idx = label_r.loc[:,select_drug].dropna()\n",
    "if(g_disperson!=None):\n",
    "    hvg,adata = ut.highly_variable_genes(data_r,min_disp=g_disperson)\n",
    "    # Rename columns if duplication exist\n",
    "    data_r.columns = adata.var_names\n",
    "    # Extract hvgs\n",
    "    data = data_r.loc[selected_idx.index,hvg]\n",
    "else:\n",
    "    data = data_r.loc[selected_idx.index,:]\n",
    "\n",
    "# Do PCA if PCA_dim!=0\n",
    "if PCA_dim !=0 :\n",
    "    data = PCA(n_components = PCA_dim).fit_transform(data)\n",
    "else:\n",
    "    data = data\n",
    "\n",
    "# Extract labels\n",
    "label = label_r.loc[selected_idx.index,select_drug]\n",
    "data_r = data_r.loc[selected_idx.index,:]\n",
    "\n",
    "# Scaling data\n",
    "mmscaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "data = mmscaler.fit_transform(data)\n",
    "label = label.values.reshape(-1,1)\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(label)\n",
    "dim_model_out = 2\n",
    "\n",
    "#label = label.values.reshape(-1,1)\n",
    "\n",
    "logging.info(np.std(data))\n",
    "logging.info(np.mean(data))\n",
    "\n",
    "# Split traning valid test set\n",
    "X_train_all, X_test, Y_train_all, Y_test = train_test_split(data, label, test_size=test_size, random_state=42)\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train_all, Y_train_all, test_size=valid_size, random_state=42)\n",
    "# sampling method\n",
    "if sampling == \"no\":\n",
    "    X_train,Y_train=sam.nosampling(X_train,Y_train)\n",
    "    logging.info(\"nosampling\")\n",
    "elif sampling ==\"upsampling\":\n",
    "    X_train,Y_train=sam.upsampling(X_train,Y_train)\n",
    "    logging.info(\"upsampling\")\n",
    "elif sampling ==\"downsampling\":\n",
    "    X_train,Y_train=sam.downsampling(X_train,Y_train)\n",
    "    logging.info(\"downsampling\")\n",
    "elif  sampling==\"SMOTE\":\n",
    "    X_train,Y_train=sam.SMOTEsampling(X_train,Y_train)\n",
    "    logging.info(\"SMOTE\")\n",
    "else:\n",
    "    logging.info(\"not a legal sampling method\")\n",
    "\n",
    "# Select the Training device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = 'cpu'\n",
    "#print(device)\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "#logging.info(device)\n",
    "torch.cuda.set_device(device)\n",
    "print(device)\n",
    "# Construct datasets and data loaders\n",
    "X_trainTensor = torch.FloatTensor(X_train).to(device)\n",
    "X_validTensor = torch.FloatTensor(X_valid).to(device)\n",
    "X_testTensor = torch.FloatTensor(X_test).to(device)\n",
    "\n",
    "Y_trainTensor = torch.LongTensor(Y_train).to(device)\n",
    "Y_validTensor = torch.LongTensor(Y_valid).to(device)\n",
    "\n",
    "# Preprocess data to tensor\n",
    "train_dataset = TensorDataset(X_trainTensor, X_trainTensor)\n",
    "valid_dataset = TensorDataset(X_validTensor, X_validTensor)\n",
    "\n",
    "X_trainDataLoader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "X_validDataLoader = DataLoader(dataset=valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# construct TensorDataset\n",
    "trainreducedDataset = TensorDataset(X_trainTensor, Y_trainTensor)\n",
    "validreducedDataset = TensorDataset(X_validTensor, Y_validTensor)\n",
    "\n",
    "trainDataLoader_p = DataLoader(dataset=trainreducedDataset, batch_size=batch_size, shuffle=True)\n",
    "validDataLoader_p = DataLoader(dataset=validreducedDataset, batch_size=batch_size, shuffle=True)\n",
    "bulk_X_allTensor = torch.FloatTensor(data).to(device)\n",
    "bulk_Y_allTensor = torch.LongTensor(label).to(device)\n",
    "dataloaders_train = {'train':trainDataLoader_p,'val':validDataLoader_p}\n",
    "print(\"bulk_X_allRensor\",bulk_X_allTensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PretrainedPredictor(\n",
       "  (encoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=15962, out_features=256, bias=True)\n",
       "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (bottleneck): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (predictor): Predictor(\n",
       "    (predictor): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=128, bias=True)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (output): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=2, bias=True)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Defined the model of predictor \n",
    "if reduce_model == \"AE\":\n",
    "    model = PretrainedPredictor(input_dim=X_train.shape[1],latent_dim=dim_au_out,h_dims=encoder_hdims, \n",
    "                            hidden_dims_predictor=preditor_hdims,output_dim=dim_model_out,\n",
    "                            pretrained_weights=None,freezed=bool(args.freeze_pretrain),drop_out=args.dropout,drop_out_predictor=args.dropout)\n",
    "if reduce_model == \"DAE\":\n",
    "    model = PretrainedPredictor(input_dim=X_train.shape[1],latent_dim=dim_au_out,h_dims=encoder_hdims, \n",
    "                            hidden_dims_predictor=preditor_hdims,output_dim=dim_model_out,\n",
    "                            pretrained_weights=None,freezed=bool(args.freeze_pretrain),drop_out=args.dropout,drop_out_predictor=args.dropout)                                \n",
    "elif reduce_model == \"VAE\":\n",
    "    model = PretrainedVAEPredictor(input_dim=X_train.shape[1],latent_dim=dim_au_out,h_dims=encoder_hdims, \n",
    "                    hidden_dims_predictor=preditor_hdims,output_dim=dim_model_out,\n",
    "                    pretrained_weights=None,freezed=bool(args.freeze_pretrain),z_reparam=bool(args.VAErepram),drop_out=args.dropout,drop_out_predictor=args.dropout)\n",
    "#print(\"@@@@@@@@@@@\")\n",
    "logging.info(\"Current model is:\")\n",
    "logging.info(model)\n",
    "#if torch.cuda.is_available():\n",
    "#    model.cuda()\n",
    "model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(selected_model)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulk_model finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dl_result = model(X_testTensor).detach().cpu().numpy()\n",
    "\n",
    "lb_results = np.argmax(dl_result,axis=1)\n",
    "#pb_results = np.max(dl_result,axis=1)\n",
    "pb_results = dl_result[:,1]\n",
    "\n",
    "report_dict = classification_report(Y_test, lb_results, output_dict=True)\n",
    "report_df = pd.DataFrame(report_dict).T\n",
    "ap_score = average_precision_score(Y_test, pb_results)\n",
    "auroc_score = roc_auc_score(Y_test, pb_results)\n",
    "\n",
    "report_df['auroc_score'] = auroc_score\n",
    "report_df['ap_score'] = ap_score\n",
    "\n",
    "report_df.to_csv(\"saved/logs/\" + reduce_model + select_drug+now + '_report.csv')\n",
    "\n",
    "#logging.info(classification_report(Y_test, lb_results))\n",
    "#logging.info(average_precision_score(Y_test, pb_results))\n",
    "#logging.info(roc_auc_score(Y_test, pb_results))\n",
    "\n",
    "model = DummyClassifier(strategy='stratified')\n",
    "model.fit(X_train, Y_train)\n",
    "yhat = model.predict_proba(X_test)\n",
    "naive_probs = yhat[:, 1]\n",
    "\n",
    "ut.plot_roc_curve(Y_test, naive_probs, pb_results, title=str(roc_auc_score(Y_test, pb_results)),\n",
    "                    path=\"saved/figures/\" + reduce_model + select_drug+now + '_roc.pdf')\n",
    "ut.plot_pr_curve(Y_test,pb_results,  title=average_precision_score(Y_test, pb_results),\n",
    "                path=\"saved/figures/\" + reduce_model + select_drug+now + '_prc.pdf')\n",
    "print(\"bulk_model finished\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
