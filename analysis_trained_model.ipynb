{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from decimal import Decimal\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import torch\n",
    "from captum.attr import IntegratedGradients\n",
    "from numpy.lib.function_base import gradient\n",
    "from sklearn import preprocessing\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import (auc, average_precision_score,\n",
    "                             classification_report, mean_squared_error,\n",
    "                             precision_recall_curve, r2_score, roc_auc_score)\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch import nn, optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from scipy.stats import pearsonr\n",
    "import DaNN.mmd as mmd\n",
    "import scanpypip.preprocessing as pp\n",
    "import trainers as t\n",
    "import utils as ut\n",
    "from models import (AEBase, CVAEBase, DaNN, Predictor, PretrainedPredictor,\n",
    "                    PretrainedVAEPredictor, TargetModel, VAEBase)\n",
    "from scanpypip.utils import get_de_dataframe\n",
    "from trajectory import trajectory\n",
    "from sklearn.feature_selection import SelectKBest,SelectFdr\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "\n",
    "DATA_MAP={\n",
    "\"GSE117872\":\"data/GSE117872/GSE117872_good_Data_TPM.txt\",\n",
    "\"GSE117309\":'data/GSE117309/filtered_gene_bc_matrices_HBCx-22/hg19/',\n",
    "\"GSE117309_TAMR\":'data/GSE117309/filtered_gene_bc_matrices_HBCx22-TAMR/hg19/',\n",
    "\"GSE121107\":'data/GSE121107/GSM3426289_untreated_out_gene_exon_tagged.dge.txt',\n",
    "\"GSE121107_1H\":'data/GSE121107/GSM3426290_entinostat_1hr_out_gene_exon_tagged.dge.txt',\n",
    "\"GSE121107_6H\":'data/GSE121107/GSM3426291_entinostat_6hr_out_gene_exon_tagged.dge.txt',\n",
    "\"GSE111014\":'data/GSE111014/',\n",
    "\"GSE110894\":\"data/GSE110894/GSE110894.csv\",\n",
    "\"GSE122843\":\"data/GSE122843/GSE122843.txt\",\n",
    "\"GSE112274\":\"data/GSE112274/GSE112274_cell_gene_FPKM.csv\",\n",
    "\"GSE116237\":\"data/GSE116237/GSE116237_bulkRNAseq_expressionMatrix.txt\",\n",
    "\"GSE108383\":\"data/GSE108383/GSE108383_Melanoma_fluidigm.txt\",\n",
    "\"GSE140440\":\"data/GSE140440/GSE140440.csv\",\n",
    "\"GSE129730\":\"data/GSE129730/GSE129730.h5ad\",\n",
    "\"GSE149383\":\"data/GSE149383/erl_total_data_2K.csv\",\n",
    "\"GSE110894_small\":\"data/GSE110894/GSE110894_small.h5ad\",\n",
    "\"MIX-Seq\":\"data/10298696\"\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"saved/models/1214*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saved/models\\\\1214data_GSE110894_drug_I.BET.762_bottle_128_edim_512,256_pdim_256,128_model_DAE_dropout_0.1_gene_F_lr_0.01_mod_new_sam_downsampling_DaNN.pkl',\n",
       " 'saved/models\\\\1214data_GSE112274_drug_GEFITINIB_bottle_64_edim_512,256_pdim_256,128_model_DAE_dropout_0.1_gene_F_lr_0.1_mod_new_sam_no_DaNN.pkl',\n",
       " 'saved/models\\\\1214data_GSE117872HN120_drug_CISPLATIN_bottle_32_edim_256,128_pdim_128,64_model_DAE_dropout_0.3_gene_F_lr_0.5_mod_new_sam_SMOTE_DaNN.pkl',\n",
       " 'saved/models\\\\1214data_GSE117872HN137_drug_CISPLATIN_bottle_32_edim_256,128_pdim_128,64_model_DAE_dropout_0.3_gene_F_lr_0.5_mod_new_sam_SMOTE_DaNN.pkl',\n",
       " 'saved/models\\\\1214data_GSE140440_drug_DOCETAXEL_bottle_512_edim_256,128_pdim_256,128_model_DAE_dropout_0.3_gene_F_lr_0.01_mod_new_sam_no_DaNN.pkl',\n",
       " 'saved/models\\\\1214data_GSE149383_drug_ERLOTINIB_bottle_512_edim_512,256_pdim_256,128_model_DAE_dropout_0.1_gene_F_lr_0.1_mod_new_sam_SMOTE_DaNN.pkl']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "# data \n",
    "parser.add_argument('--source_data', type=str, default='data/ALL_expression.csv')\n",
    "parser.add_argument('--label_path', type=str, default='data/ALL_label_binary_wf.csv')\n",
    "parser.add_argument('--target_data', type=str, default=\"GSE110894\")\n",
    "parser.add_argument('--drug', type=str, default='I-BET-762')\n",
    "parser.add_argument('--missing_value', type=int, default=1)\n",
    "parser.add_argument('--test_size', type=float, default=0.2)\n",
    "parser.add_argument('--valid_size', type=float, default=0.2)\n",
    "parser.add_argument('--var_genes_disp', type=float, default=0)\n",
    "parser.add_argument('--min_n_genes', type=int, default=0)\n",
    "parser.add_argument('--max_n_genes', type=int, default=20000)\n",
    "parser.add_argument('--min_g', type=int, default=200)\n",
    "parser.add_argument('--min_c', type=int, default=3)\n",
    "parser.add_argument('--cluster_res', type=float, default=0.3)\n",
    "parser.add_argument('--remove_genes', type=int, default=1)\n",
    "parser.add_argument('--mmd_weight', type=float, default=0.25)\n",
    "\n",
    "# train\n",
    "parser.add_argument('--source_model_path','-s', type=str, default='saved/models/BET_dw_256_AE.pkl')\n",
    "parser.add_argument('--target_model_path', '-p',  type=str, default='saved/models/GSE110894_I-BET-762256AE')\n",
    "parser.add_argument('--pretrain', type=str, default='saved/models/GSE110894_I-BET-762_256_ae.pkl')\n",
    "parser.add_argument('--transfer', type=str, default=\"DaNN\")\n",
    "\n",
    "parser.add_argument('--lr', type=float, default=1e-2)\n",
    "parser.add_argument('--epochs', type=int, default=500)\n",
    "parser.add_argument('--batch_size', type=int, default=200)\n",
    "parser.add_argument('--bottleneck', type=int, default=256)\n",
    "parser.add_argument('--dimreduce', type=str, default=\"DAE\")\n",
    "parser.add_argument('--predictor', type=str, default=\"DNN\")\n",
    "parser.add_argument('--freeze_pretrain', type=int, default=0)\n",
    "parser.add_argument('--source_h_dims', type=str, default=\"256,256\")\n",
    "parser.add_argument('--target_h_dims', type=str, default=\"256,256\")\n",
    "parser.add_argument('--p_h_dims', type=str, default=\"128,64\")\n",
    "parser.add_argument('--predition', type=str, default=\"classification\")\n",
    "parser.add_argument('--VAErepram', type=int, default=1)\n",
    "parser.add_argument('--batch_id', type=str, default=\"HN137\")\n",
    "parser.add_argument('--load_target_model', type=int, default=0)\n",
    "parser.add_argument('--GAMMA_mmd', type=int, default=1000)\n",
    "parser.add_argument('--dropout', type=float, default=0.3,help='dropout')\n",
    "\n",
    "parser.add_argument('--runs', type=int, default=1)\n",
    "\n",
    "# Analysis\n",
    "parser.add_argument('--n_DL_genes', type=int, default=50)\n",
    "parser.add_argument('--n_DE_genes', type=int, default=50)\n",
    "\n",
    "\n",
    "# misc\n",
    "parser.add_argument('--message', '-m',  type=str, default='message')\n",
    "parser.add_argument('--output_name', '-n',  type=str, default='saved/results')\n",
    "parser.add_argument('--logging_file', '-l',  type=str, default='saved/logs/transfer_')\n",
    "\n",
    "#\n",
    "args, unknown = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GSE110894', 'I.BET.762', '128', '512,256', '256,128', 'DAE', '0.1', 'F', '0.01', 'new', 'downsampling']\n",
      "['saved/models\\\\1214data', 'drug', 'bottle', 'edim', 'pdim', 'model', 'dropout', 'gene', 'lr', 'mod', 'sam']\n"
     ]
    }
   ],
   "source": [
    "## Testing the args covering\n",
    "selected_model = files[0]\n",
    "split_name = select_model.split(\"_\")\n",
    "print(split_name[1::2])\n",
    "print(split_name[0::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "paras = (split_name[1::2])\n",
    "para_names = (split_name[0::2])\n",
    "\n",
    "args.source_h_dims = paras[3]\n",
    "args.target_h_dims = paras[3]\n",
    "args.p_h_dims = paras[4]\n",
    "args.bottleneck = int(paras[2])\n",
    "args.drug = paras[1]\n",
    "args.dropout = float(paras[6])\n",
    "\n",
    "if(paras[0].find(\"GSE117872\")>=0):\n",
    "    args.target_data = \"GSE117872\"\n",
    "    args.batch_id = paras[0].split(\"GSE117872\")[1]\n",
    "elif(paras[0].find(\"MIX-Seq\")>=0):\n",
    "    args.target_data = \"MIX-Seq\"\n",
    "    args.batch_id = paras[0].split(\"MIX-Seq\")[1]    \n",
    "else:\n",
    "    args.target_data = paras[0]\n",
    "    \n",
    "args.target_model_path = selected_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GSE110894',\n",
       " 'I.BET.762',\n",
       " '128',\n",
       " '512,256',\n",
       " '256,128',\n",
       " 'DAE',\n",
       " '0.1',\n",
       " 'F',\n",
       " '0.01',\n",
       " 'new',\n",
       " 'downsampling']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read parameters\n",
    "data_name = args.target_data\n",
    "epochs = args.epochs\n",
    "dim_au_out = args.bottleneck #8, 16, 32, 64, 128, 256,512\n",
    "na = args.missing_value\n",
    "data_path = DATA_MAP[args.target_data]\n",
    "test_size = args.test_size\n",
    "select_drug = args.drug\n",
    "freeze = args.freeze_pretrain\n",
    "valid_size = args.valid_size\n",
    "g_disperson = args.var_genes_disp\n",
    "min_n_genes = args.min_n_genes\n",
    "max_n_genes = args.max_n_genes\n",
    "source_model_path = args.source_model_path\n",
    "target_model_path = args.target_model_path \n",
    "log_path = args.logging_file\n",
    "batch_size = args.batch_size\n",
    "encoder_hdims = args.source_h_dims.split(\",\")\n",
    "encoder_hdims = list(map(int, encoder_hdims))\n",
    "source_data_path = args.source_data \n",
    "pretrain = args.pretrain\n",
    "prediction = args.predition\n",
    "data_name = args.target_data\n",
    "label_path = args.label_path\n",
    "reduce_model = args.dimreduce\n",
    "predict_hdims = args.p_h_dims.split(\",\")\n",
    "predict_hdims = list(map(int, predict_hdims))\n",
    "leiden_res = args.cluster_res\n",
    "load_model = bool(args.load_target_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(data_name!=\"MIX-Seq\"):\n",
    "    adata = pp.read_sc_file(data_path)\n",
    "\n",
    "    if data_name == 'GSE117872':\n",
    "        adata =  ut.specific_process(adata,dataname=data_name,select_origin=args.batch_id)\n",
    "    elif data_name =='GSE122843':\n",
    "        adata =  ut.specific_process(adata,dataname=data_name)\n",
    "    elif data_name =='GSE110894':\n",
    "        adata =  ut.specific_process(adata,dataname=data_name)\n",
    "    elif data_name =='GSE112274':\n",
    "        adata =  ut.specific_process(adata,dataname=data_name)\n",
    "    elif data_name =='GSE116237':\n",
    "        adata =  ut.specific_process(adata,dataname=data_name)\n",
    "    elif data_name =='GSE108383':\n",
    "        adata =  ut.specific_process(adata,dataname=data_name)\n",
    "    elif data_name =='GSE140440':\n",
    "        adata =  ut.specific_process(adata,dataname=data_name)\n",
    "    elif data_name =='GSE129730':\n",
    "        adata =  ut.specific_process(adata,dataname=data_name)\n",
    "    elif data_name =='GSE149383':\n",
    "        adata =  ut.specific_process(adata,dataname=data_name)\n",
    "    else:\n",
    "        adata=adata\n",
    "else:\n",
    "    # Can be expt1, expt3, and expt10\n",
    "    # Add process mix-seq\n",
    "    expID = args.batch_id\n",
    "    drug_path = args.drug.capitalize()\n",
    "    adata = ut.process_mix_seq(drug=drug_path,expt=expID)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 1504 × 25921\n",
       "    obs: 'Plate#', 'Well position', 'Sample name', 'Index-Sort condition', 'Well index', 'sensitive', 'sensitivity'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plate#</th>\n",
       "      <th>Well position</th>\n",
       "      <th>Sample name</th>\n",
       "      <th>Index-Sort condition</th>\n",
       "      <th>Well index</th>\n",
       "      <th>sensitive</th>\n",
       "      <th>sensitivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RPI1_A3</th>\n",
       "      <td>RPI1</td>\n",
       "      <td>A3</td>\n",
       "      <td>MA9 IBET RESISTANT CELLS</td>\n",
       "      <td>GR+</td>\n",
       "      <td>GGTCTATG</td>\n",
       "      <td>0</td>\n",
       "      <td>Resistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPI1_A4</th>\n",
       "      <td>RPI1</td>\n",
       "      <td>A4</td>\n",
       "      <td>MA9 IBET RESISTANT CELLS</td>\n",
       "      <td>GR+</td>\n",
       "      <td>GTCCGAAT</td>\n",
       "      <td>0</td>\n",
       "      <td>Resistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPI1_A5</th>\n",
       "      <td>RPI1</td>\n",
       "      <td>A5</td>\n",
       "      <td>MA9 IBET RESISTANT CELLS</td>\n",
       "      <td>GR+</td>\n",
       "      <td>TAGTGCGT</td>\n",
       "      <td>0</td>\n",
       "      <td>Resistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPI1_A6</th>\n",
       "      <td>RPI1</td>\n",
       "      <td>A6</td>\n",
       "      <td>MA9 IBET RESISTANT CELLS</td>\n",
       "      <td>GR+</td>\n",
       "      <td>GACTGTAC</td>\n",
       "      <td>0</td>\n",
       "      <td>Resistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPI1_A7</th>\n",
       "      <td>RPI1</td>\n",
       "      <td>A7</td>\n",
       "      <td>MA9 IBET RESISTANT CELLS</td>\n",
       "      <td>GR+</td>\n",
       "      <td>TCCAGTAG</td>\n",
       "      <td>0</td>\n",
       "      <td>Resistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPI7_P18</th>\n",
       "      <td>RPI7</td>\n",
       "      <td>P18</td>\n",
       "      <td>MA9 IBET RESISTANT CELLS- WITHDRAWAL</td>\n",
       "      <td>GR-</td>\n",
       "      <td>ACGTGTGT</td>\n",
       "      <td>0</td>\n",
       "      <td>Resistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPI7_P19</th>\n",
       "      <td>RPI7</td>\n",
       "      <td>P19</td>\n",
       "      <td>MA9 IBET RESISTANT CELLS- WITHDRAWAL</td>\n",
       "      <td>GR-</td>\n",
       "      <td>TCAGCGTA</td>\n",
       "      <td>0</td>\n",
       "      <td>Resistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPI7_P20</th>\n",
       "      <td>RPI7</td>\n",
       "      <td>P20</td>\n",
       "      <td>MA9 IBET RESISTANT CELLS- WITHDRAWAL</td>\n",
       "      <td>GR-</td>\n",
       "      <td>AGAAGAGG</td>\n",
       "      <td>0</td>\n",
       "      <td>Resistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPI7_P21</th>\n",
       "      <td>RPI7</td>\n",
       "      <td>P21</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>EMPTY</td>\n",
       "      <td>TATCCGGA</td>\n",
       "      <td>1</td>\n",
       "      <td>Sensitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPI7_P22</th>\n",
       "      <td>RPI7</td>\n",
       "      <td>P22</td>\n",
       "      <td>MA9 IBET RESISTANT CELLS- WITHDRAWAL</td>\n",
       "      <td>GR-</td>\n",
       "      <td>ACGACTCA</td>\n",
       "      <td>0</td>\n",
       "      <td>Resistant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1504 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Plate# Well position                           Sample name  \\\n",
       "RPI1_A3    RPI1            A3              MA9 IBET RESISTANT CELLS   \n",
       "RPI1_A4    RPI1            A4              MA9 IBET RESISTANT CELLS   \n",
       "RPI1_A5    RPI1            A5              MA9 IBET RESISTANT CELLS   \n",
       "RPI1_A6    RPI1            A6              MA9 IBET RESISTANT CELLS   \n",
       "RPI1_A7    RPI1            A7              MA9 IBET RESISTANT CELLS   \n",
       "...         ...           ...                                   ...   \n",
       "RPI7_P18   RPI7           P18  MA9 IBET RESISTANT CELLS- WITHDRAWAL   \n",
       "RPI7_P19   RPI7           P19  MA9 IBET RESISTANT CELLS- WITHDRAWAL   \n",
       "RPI7_P20   RPI7           P20  MA9 IBET RESISTANT CELLS- WITHDRAWAL   \n",
       "RPI7_P21   RPI7           P21                                 EMPTY   \n",
       "RPI7_P22   RPI7           P22  MA9 IBET RESISTANT CELLS- WITHDRAWAL   \n",
       "\n",
       "         Index-Sort condition Well index  sensitive sensitivity  \n",
       "RPI1_A3                   GR+   GGTCTATG          0   Resistant  \n",
       "RPI1_A4                   GR+   GTCCGAAT          0   Resistant  \n",
       "RPI1_A5                   GR+   TAGTGCGT          0   Resistant  \n",
       "RPI1_A6                   GR+   GACTGTAC          0   Resistant  \n",
       "RPI1_A7                   GR+   TCCAGTAG          0   Resistant  \n",
       "...                       ...        ...        ...         ...  \n",
       "RPI7_P18                  GR-   ACGTGTGT          0   Resistant  \n",
       "RPI7_P19                  GR-   TCAGCGTA          0   Resistant  \n",
       "RPI7_P20                  GR-   AGAAGAGG          0   Resistant  \n",
       "RPI7_P21                EMPTY   TATCCGGA          1   Sensitive  \n",
       "RPI7_P22                  GR-   ACGACTCA          0   Resistant  \n",
       "\n",
       "[1504 rows x 7 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\anndata\\_core\\anndata.py:1094: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  if not is_categorical(df_full[k]):\n",
      "D:\\Anaconda3\\lib\\site-packages\\anndata\\_core\\anndata.py:1094: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  if not is_categorical(df_full[k]):\n",
      "D:\\Anaconda3\\lib\\site-packages\\anndata\\_core\\anndata.py:1094: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  if not is_categorical(df_full[k]):\n",
      "D:\\Anaconda3\\lib\\site-packages\\scanpy\\preprocessing\\_normalization.py:155: UserWarning: Revieved a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1419, 21182)\n"
     ]
    }
   ],
   "source": [
    "sc.pp.filter_cells(adata, min_genes=200)\n",
    "sc.pp.filter_genes(adata, min_cells=3)\n",
    "\n",
    "adata = pp.cal_ncount_ngenes(adata)\n",
    "adata = pp.receipe_my(adata,l_n_genes=min_n_genes,r_n_genes=max_n_genes,filter_mincells=args.min_c,percent_mito = 100,\n",
    "                        filter_mingenes=args.min_g,normalize=True,log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.highly_variable_genes(adata,min_disp=g_disperson,max_disp=np.inf,max_mean=6)\n",
    "adata.raw = adata\n",
    "adata = adata[:, adata.var.highly_variable]\n",
    "data=adata.X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "View of AnnData object with n_obs × n_vars = 1419 × 6644\n",
       "    obs: 'Plate#', 'Well position', 'Sample name', 'Index-Sort condition', 'Well index', 'sensitive', 'sensitivity', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt-', 'pct_counts_mt-', 'total_counts_rps', 'pct_counts_rps', 'total_counts_rpl', 'pct_counts_rpl'\n",
       "    var: 'n_cells', 'mt-', 'rps', 'rpl', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'\n",
       "    uns: 'log1p', 'hvg'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.pca(adata,svd_solver='arpack')\n",
    "sc.pp.neighbors(adata, n_neighbors=10)\n",
    "# Generate cluster labels\n",
    "sc.tl.leiden(adata,resolution=leiden_res)\n",
    "sc.tl.umap(adata)\n",
    "adata.obs['leiden_origin']= adata.obs['leiden']\n",
    "adata.obsm['X_umap_origin']= adata.obsm['X_umap']\n",
    "data_c = adata.obs['leiden'].astype(\"long\").to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmscaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "try:\n",
    "    data = mmscaler.fit_transform(data)\n",
    "\n",
    "except:\n",
    "    logging.warning(\"Sparse data , transfrom to dense\")\n",
    "\n",
    "    # Process sparse data\n",
    "    data = data.todense()\n",
    "    data = mmscaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I.BET.762'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_drug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X5.FLUOROURACIL', 'AZ960', 'AZD2014', 'AZD4547', 'AZD5363', 'AZD5438',\n",
       "       'AZD6482', 'AZD7762', 'AZD8055', 'BI.2536', 'BIBR.1532', 'BMS.345541',\n",
       "       'BMS.754807', 'GSK1904529A', 'I.BET.762', 'LY2109761', 'MG.132',\n",
       "       'MK.1775', 'MK.2206', 'OSI.027', 'OTX015', 'P22077', 'PLX.4720',\n",
       "       'PRT062607', 'VE.822', 'AFATINIB', 'ALISERTIB', 'ALPELISIB', 'AXITINIB',\n",
       "       'BORTEZOMIB', 'BUPARLISIB', 'CAMPTOTHECIN', 'CARMUSTINE', 'CEDIRANIB',\n",
       "       'CISPLATIN', 'CRIZOTINIB', 'CYCLOPHOSPHAMIDE', 'CYTARABINE',\n",
       "       'DABRAFENIB', 'DASATINIB', 'DINACICLIB', 'DOCETAXEL', 'ENTINOSTAT',\n",
       "       'EPIRUBICIN', 'ERLOTINIB', 'FLUDARABINE', 'FORETINIB', 'FULVESTRANT',\n",
       "       'GEFITINIB', 'GEMCITABINE', 'IBRUTINIB', 'IRINOTECAN', 'LAPATINIB',\n",
       "       'LINSITINIB', 'MITOXANTRONE', 'NAVITOCLAX', 'NELARABINE', 'NILOTINIB',\n",
       "       'NIRAPARIB', 'OLAPARIB', 'OSIMERTINIB', 'OXALIPLATIN', 'PACLITAXEL',\n",
       "       'PALBOCICLIB', 'PEVONEDISTAT', 'RIBOCICLIB', 'RUXOLITINIB',\n",
       "       'SELUMETINIB', 'SORAFENIB', 'TALAZOPARIB', 'TAMOXIFEN', 'TASELISIB',\n",
       "       'TEMOZOLOMIDE', 'TENIPOSIDE', 'TOPOTECAN', 'TOZASERTIB', 'TRAMETINIB',\n",
       "       'UPROSERTIB', 'VENETOCLAX', 'VINBLASTINE', 'VINCRISTINE', 'VINORELBINE',\n",
       "       'VORINOSTAT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_r.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "Xtarget_train, Xtarget_valid, Ctarget_train, Ctarget_valid = train_test_split(data,data_c, test_size=valid_size, random_state=42)\n",
    "\n",
    "\n",
    "# Select the device of gpu\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = \"cpu\"\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "#logging.info(device)\n",
    "print(device)\n",
    "torch.cuda.set_device(device)\n",
    "\n",
    "# Construct datasets and data loaders\n",
    "Xtarget_trainTensor = torch.FloatTensor(Xtarget_train).to(device)\n",
    "Xtarget_validTensor = torch.FloatTensor(Xtarget_valid).to(device)\n",
    "#print(Xtarget_validTensor.shape)\n",
    "# Use leiden label if CVAE is applied \n",
    "Ctarget_trainTensor = torch.LongTensor(Ctarget_train).to(device)\n",
    "Ctarget_validTensor = torch.LongTensor(Ctarget_valid).to(device)\n",
    "#print(\"C\",Ctarget_validTensor )\n",
    "X_allTensor = torch.FloatTensor(data).to(device)\n",
    "C_allTensor = torch.LongTensor(data_c).to(device)\n",
    "\n",
    "\n",
    "train_dataset = TensorDataset(Xtarget_trainTensor, Ctarget_trainTensor)\n",
    "valid_dataset = TensorDataset(Xtarget_validTensor, Ctarget_validTensor)\n",
    "\n",
    "Xtarget_trainDataLoader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "Xtarget_validDataLoader = DataLoader(dataset=valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataloaders_pretrain = {'train':Xtarget_trainDataLoader,'val':Xtarget_validDataLoader}\n",
    "#print('START SECTION OF LOADING SC DATA TO THE TENSORS')\n",
    "################################################# START SECTION OF LOADING SC DATA TO THE TENSORS #################################################\n",
    "\n",
    "################################################# START SECTION OF LOADING BULK DATA  #################################################\n",
    "# Read source data\n",
    "data_r=pd.read_csv(source_data_path,index_col=0)\n",
    "label_r=pd.read_csv(label_path,index_col=0)\n",
    "label_r=label_r.fillna(na)\n",
    "\n",
    "# Extract labels\n",
    "selected_idx = label_r.loc[:,select_drug]!=na\n",
    "label = label_r.loc[selected_idx.index,select_drug]\n",
    "data_r = data_r.loc[selected_idx.index,:]\n",
    "label = label.values.reshape(-1,1)\n",
    "\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "label = le.fit_transform(label)\n",
    "dim_model_out = 2\n",
    "\n",
    "# Process source data\n",
    "mmscaler = preprocessing.MinMaxScaler()\n",
    "source_data = mmscaler.fit_transform(data_r)\n",
    "\n",
    "# Split source data\n",
    "Xsource_train_all, Xsource_test, Ysource_train_all, Ysource_test = train_test_split(source_data,label, test_size=test_size, random_state=42)\n",
    "Xsource_train, Xsource_valid, Ysource_train, Ysource_valid = train_test_split(Xsource_train_all,Ysource_train_all, test_size=valid_size, random_state=42)\n",
    "\n",
    "# Transform source data\n",
    "# Construct datasets and data loaders\n",
    "Xsource_trainTensor = torch.FloatTensor(Xsource_train).to(device)\n",
    "Xsource_validTensor = torch.FloatTensor(Xsource_valid).to(device)\n",
    "\n",
    "Ysource_trainTensor = torch.LongTensor(Ysource_train).to(device)\n",
    "Ysource_validTensor = torch.LongTensor(Ysource_valid).to(device)\n",
    "\n",
    "sourcetrain_dataset = TensorDataset(Xsource_trainTensor, Ysource_trainTensor)\n",
    "sourcevalid_dataset = TensorDataset(Xsource_validTensor, Ysource_validTensor)\n",
    "\n",
    "\n",
    "Xsource_trainDataLoader = DataLoader(dataset=sourcetrain_dataset, batch_size=batch_size, shuffle=True)\n",
    "Xsource_validDataLoader = DataLoader(dataset=sourcevalid_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataloaders_source = {'train':Xsource_trainDataLoader,'val':Xsource_validDataLoader}\n",
    "#print('END SECTION OF LOADING BULK DATA')\n",
    "################################################# END SECTION OF LOADING BULK DATA  #################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################# START SECTION OF MODEL CUNSTRUCTION  #################################################\n",
    "# Construct target encoder\n",
    "if reduce_model == \"AE\":\n",
    "    encoder = AEBase(input_dim=data.shape[1],latent_dim=dim_au_out,h_dims=encoder_hdims,drop_out=args.dropout)\n",
    "    loss_function_e = nn.MSELoss()\n",
    "elif reduce_model == \"VAE\":\n",
    "    encoder = VAEBase(input_dim=data.shape[1],latent_dim=dim_au_out,h_dims=encoder_hdims,drop_out=args.dropout)\n",
    "if reduce_model == \"DAE\":\n",
    "    encoder = AEBase(input_dim=data.shape[1],latent_dim=dim_au_out,h_dims=encoder_hdims,drop_out=args.dropout)\n",
    "    loss_function_e = nn.MSELoss()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_model_out = 2\n",
    "# Load AE model\n",
    "if reduce_model == \"AE\":\n",
    "    source_model = PretrainedPredictor(input_dim=Xsource_train.shape[1],latent_dim=dim_au_out,h_dims=encoder_hdims, \n",
    "            hidden_dims_predictor=predict_hdims,output_dim=dim_model_out,\n",
    "            pretrained_weights=None,freezed=freeze,drop_out=args.dropout,drop_out_predictor=args.dropout)\n",
    "\n",
    "    #source_model.load_state_dict(torch.load(selected_model))\n",
    "    source_encoder = source_model\n",
    "if reduce_model == \"DAE\":\n",
    "    source_model = PretrainedPredictor(input_dim=Xsource_train.shape[1],latent_dim=dim_au_out,h_dims=encoder_hdims, \n",
    "            hidden_dims_predictor=predict_hdims,output_dim=dim_model_out,\n",
    "            pretrained_weights=None,freezed=freeze,drop_out=args.dropout,drop_out_predictor=args.dropout)\n",
    "\n",
    "    #source_model.load_state_dict(torch.load(selected_model))\n",
    "    source_encoder = source_model    \n",
    "# Load VAE model\n",
    "elif reduce_model in [\"VAE\"]:\n",
    "    source_model = PretrainedVAEPredictor(input_dim=Xsource_train.shape[1],latent_dim=dim_au_out,h_dims=encoder_hdims, \n",
    "            hidden_dims_predictor=predict_hdims,output_dim=dim_model_out,\n",
    "            pretrained_weights=None,freezed=freeze,z_reparam=bool(args.VAErepram),drop_out=args.dropout,drop_out_predictor=args.dropout)\n",
    "    #source_model.load_state_dict(torch.load(selected_model))\n",
    "    source_encoder = source_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DaNN(\n",
       "  (source_model): PretrainedPredictor(\n",
       "    (encoder): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=15962, out_features=512, bias=True)\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (predictor): Predictor(\n",
       "      (predictor): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (output): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=2, bias=True)\n",
       "        (1): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (target_model): AEBase(\n",
       "    (encoder): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=6644, out_features=512, bias=True)\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (decoder_input): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (decoder): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (final_layer): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=6644, bias=True)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set DaNN model\n",
    "DaNN_model = DaNN(source_model=source_encoder,target_model=encoder)\n",
    "DaNN_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DaNN_model.load_state_dict(torch.load(selected_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = DaNN_model.target_model\n",
    "source_model = DaNN_model.source_model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
